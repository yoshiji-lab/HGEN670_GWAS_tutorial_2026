{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# sgkit GWAS tutorial in Google Colab (classroom version)\nThis notebook adapts the official sgkit GWAS tutorial to run smoothly in Colab.\n\n**What students will do**\n1) Install sgkit with VCF support\n2) Download a small public 1000 Genomes VCF (≈20MB) and sample annotations\n3) Convert VCF → Zarr (faster downstream)\n4) Run a toy GWAS for the provided `CaffeineConsumption` trait\n5) Show why population structure confounds GWAS, then correct it using PCA covariates\n\nSource data and overall flow follow the sgkit GWAS tutorial. citeturn1view0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Colab setup\n# VCF support is an \"extra\" in sgkit (installs cyvcf2). citeturn10search0\n!pip -q install 'sgkit[vcf]'"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport xarray as xr\nimport matplotlib.pyplot as plt\n\nimport sgkit as sg\nfrom sgkit.io.vcf import vcf_to_zarr\n\nprint(\"sgkit version:\", sg.__version__)\nxr.set_options(display_expand_attrs=False, display_expand_data_vars=True);"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Download public toy data\nWe use the same small public 1000 Genomes subset that the sgkit tutorial uses. citeturn1view0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from pathlib import Path\nimport requests\n\nVCF_URL = \"https://storage.googleapis.com/sgkit-gwas-tutorial/1kg.vcf.bgz\"\nVCF_PATH = Path(\"1kg.vcf.bgz\")\n\nif not VCF_PATH.exists():\n    print(\"Downloading VCF...\")\n    r = requests.get(VCF_URL, stream=True)\n    r.raise_for_status()\n    with open(VCF_PATH, \"wb\") as f:\n        for chunk in r.iter_content(chunk_size=1<<20):\n            if chunk:\n                f.write(chunk)\n    print(\"Saved:\", VCF_PATH, \"bytes:\", VCF_PATH.stat().st_size)\nelse:\n    print(\"VCF already exists:\", VCF_PATH, \"bytes:\", VCF_PATH.stat().st_size)\n\nANNOTATIONS_URL = \"https://storage.googleapis.com/sgkit-gwas-tutorial/1kg_annotations.txt\"\ndf_anno = pd.read_csv(ANNOTATIONS_URL, sep=\"\\t\", index_col=\"Sample\")\ndf_anno.head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Convert VCF → Zarr and load\nZarr is a chunked format that makes downstream operations much faster. citeturn1view0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "ZARR_PATH = Path(\"1kg.zarr\")\n\nif not ZARR_PATH.exists():\n    print(\"Converting VCF → Zarr (first run only)...\")\n    vcf_to_zarr(\n        str(VCF_PATH),\n        str(ZARR_PATH),\n        max_alt_alleles=1,\n        fields=[\"FORMAT/GT\", \"FORMAT/DP\", \"FORMAT/GQ\", \"FORMAT/AD\"],\n        field_defs={\"FORMAT/AD\": {\"Number\": \"R\"}},\n    )\nelse:\n    print(\"Zarr already exists:\", ZARR_PATH)\n\nds = sg.load_dataset(str(ZARR_PATH))\nds"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Attach sample annotations\nWe join the sample annotations (sex, superpopulation, caffeine intake, etc.) onto the genotype dataset. citeturn8view3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "ds_anno = df_anno.to_xarray().rename({\"Sample\": \"samples\"})\nds = ds.set_index({\"samples\": \"sample_id\"})\nds = ds.merge(ds_anno, join=\"left\")\nds = ds.reset_index(\"samples\").reset_coords(drop=True)\n\n# Keep only samples with non-missing trait values (defensive)\nds = ds.sel(samples=~xr.ufuncs.isnan(ds[\"CaffeineConsumption\"]))\nprint(\"Samples:\", int(ds.dims[\"samples\"]), \"Variants:\", int(ds.dims[\"variants\"]))\nds[[\"sample_id\", \"SuperPopulation\", \"isFemale\", \"CaffeineConsumption\"]].isel(samples=slice(5))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Basic variant QC (MAF + HWE)\nThis is a minimal QC step for teaching purposes.\nWe compute allele frequencies and Hardy-Weinberg p-values, then keep common-ish variants. citeturn13view0turn12view1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Variant summary statistics\nds = sg.variant_stats(ds)  # adds variant_allele_frequency, call rate, etc. citeturn12view0\nds = sg.hardy_weinberg_test(ds)  # adds variant_hwe_p_value citeturn12view1\n\n# Filter: AF > 1% and HWE p > 1e-6 (same thresholds used in the tutorial) citeturn13view0\naf_alt = ds[\"variant_allele_frequency\"][:, 1]\nds = ds.sel(variants=(af_alt > 0.01) & (ds[\"variant_hwe_p_value\"] > 1e-6))\n\nprint(\"After QC -> Samples:\", int(ds.dims[\"samples\"]), \"Variants:\", int(ds.dims[\"variants\"]))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) GWAS: linear regression per SNP\nWe regress the phenotype on genotype dosage (0/1/2). citeturn9view3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Dosage = number of alternate alleles\nds[\"call_dosage\"] = ds.call_genotype.sum(dim=\"ploidy\")\n\n# GWAS without population-structure covariates (intentionally confounded)\nds_lr0 = sg.gwas_linear_regression(\n    ds,\n    dosage=\"call_dosage\",\n    add_intercept=True,\n    covariates=[],\n    traits=[\"CaffeineConsumption\"],\n)\nds_lr0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Simple QQ + Manhattan plots (matplotlib only)\nimport math\n\ndef qq_plot(pvals, title=\"QQ plot\"):\n    p = np.asarray(pvals, dtype=float)\n    p = np.clip(p, np.finfo(float).tiny, 1.0)\n    p.sort()\n    n = len(p)\n    exp = -np.log10((np.arange(1, n + 1) - 0.5) / n)\n    obs = -np.log10(p)\n    mx = math.ceil(max(exp.max(), obs.max()))\n\n    plt.figure(figsize=(5, 5))\n    plt.scatter(exp, obs, s=6)\n    plt.plot([0, mx], [0, mx], linestyle=\"--\")\n    plt.xlim(0, mx); plt.ylim(0, mx)\n    plt.xlabel(\"Expected -log10(p)\")\n    plt.ylabel(\"Observed -log10(p)\")\n    plt.title(title)\n    plt.tight_layout()\n    plt.show()\n\ndef manhattan_plot(ds_lr, title=\"Manhattan plot\", genomewide_line=5e-8):\n    # Use contig name if present; otherwise fall back to numeric contig codes\n    if \"variant_contig_name\" in ds_lr:\n        chr_name = ds_lr[\"variant_contig_name\"].values\n    else:\n        chr_name = ds_lr[\"variant_contig\"].values.astype(str)\n\n    pos = ds_lr[\"variant_position\"].values\n    p = ds_lr[\"variant_linreg_p_value\"].squeeze().values\n    p = np.clip(p, np.finfo(float).tiny, 1.0)\n    mlogp = -np.log10(p)\n\n    df = pd.DataFrame({\"CHR\": chr_name, \"BP\": pos, \"MLOGP\": mlogp})\n    # sort chromosomes roughly numerically where possible\n    def chr_key(x):\n        try:\n            return (0, int(x))\n        except Exception:\n            return (1, str(x))\n    chr_order = sorted(df[\"CHR\"].unique(), key=chr_key)\n    offsets = {}\n    cur = 0\n    ticks = []\n    ticklabels = []\n    for c in chr_order:\n        m = df.loc[df[\"CHR\"] == c, \"BP\"].max()\n        offsets[c] = cur\n        ticks.append(cur + m / 2)\n        ticklabels.append(c)\n        cur += m + 1_000_000  # gap\n\n    df[\"X\"] = df.apply(lambda r: r[\"BP\"] + offsets[r[\"CHR\"]], axis=1)\n\n    plt.figure(figsize=(12, 4))\n    plt.scatter(df[\"X\"], df[\"MLOGP\"], s=4)\n    plt.axhline(-np.log10(genomewide_line), linestyle=\"--\")\n    plt.xticks(ticks, ticklabels, rotation=0)\n    plt.xlabel(\"Chromosome\")\n    plt.ylabel(\"-log10(p)\")\n    plt.title(title)\n    plt.tight_layout()\n    plt.show()\n\np0 = ds_lr0[\"variant_linreg_p_value\"].squeeze().values\nqq_plot(p0, title=\"QQ (no covariates; typically inflated)\")\nmanhattan_plot(ds_lr0, title=\"Manhattan (no covariates; confounded)\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Correct for ancestry using PCA covariates\nWe compute PCs from genotype data and include the first few PCs + sex as covariates.\nThis follows the approach in the sgkit GWAS tutorial. citeturn9view1turn9view2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# PCA on alternate-allele counts\nds_pca = sg.stats.pca.count_call_alternate_alleles(ds)  # citeturn9view1\n\n# Filter variants for PCA: remove variants with missing counts or zero variance (as in tutorial) citeturn9view1\nvariant_mask = ((ds_pca.call_alternate_allele_count < 0).any(dim=\"samples\")) |                (ds_pca.call_alternate_allele_count.std(dim=\"samples\") <= 0.0)\nds_pca = ds_pca.sel(variants=~variant_mask)\n\nds_pca = sg.pca(ds_pca)\nprint(ds_pca.sample_pca_explained_variance_ratio.values[:5])"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Plot PC1 vs PC2, colored by SuperPopulation\npc = ds_pca.sample_pca_projection.values\npop = ds[\"SuperPopulation\"].values  # same sample order\npops = pd.Categorical(pop)\n\nplt.figure(figsize=(6, 5))\nfor lvl in pops.categories:\n    m = (pops == lvl)\n    plt.scatter(pc[m, 0], pc[m, 1], s=12, label=str(lvl), alpha=0.8)\nplt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\nplt.title(\"PCA of genotypes (colored by superpopulation)\")\nplt.legend(title=\"SuperPopulation\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Copy the first 3 PCs back to the full dataset, then rerun GWAS with covariates citeturn9view2\nds[\"sample_pca_0\"] = ((\"samples\",), ds_pca.sample_pca_projection[:, 0].values)\nds[\"sample_pca_1\"] = ((\"samples\",), ds_pca.sample_pca_projection[:, 1].values)\nds[\"sample_pca_2\"] = ((\"samples\",), ds_pca.sample_pca_projection[:, 2].values)\n\nds_lr = sg.gwas_linear_regression(\n    ds,\n    dosage=\"call_dosage\",\n    add_intercept=True,\n    covariates=[\"isFemale\", \"sample_pca_0\", \"sample_pca_1\", \"sample_pca_2\"],\n    traits=[\"CaffeineConsumption\"],\n)\n\np = ds_lr[\"variant_linreg_p_value\"].squeeze().values\nqq_plot(p, title=\"QQ (sex + 3 PCs; typically better calibrated)\")\nmanhattan_plot(ds_lr, title=\"Manhattan (sex + 3 PCs)\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7) Export top hits (optional)\nThis makes it easy for students to inspect the top associations and download them."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Make a results table and show top hits\nres = pd.DataFrame({\n    \"CHR\": (ds_lr[\"variant_contig_name\"].values if \"variant_contig_name\" in ds_lr else ds_lr[\"variant_contig\"].values),\n    \"BP\": ds_lr[\"variant_position\"].values,\n    \"ID\": ds_lr[\"variant_id\"].values if \"variant_id\" in ds_lr else np.arange(ds_lr.dims[\"variants\"]),\n    \"BETA\": ds_lr[\"variant_linreg_beta\"].squeeze().values,\n    \"T\": ds_lr[\"variant_linreg_t_value\"].squeeze().values,\n    \"P\": ds_lr[\"variant_linreg_p_value\"].squeeze().values,\n})\nres = res.sort_values(\"P\")\nres.head(10)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Save as TSV in the Colab VM (download from the left panel if needed)\nout = \"sgkit_caffeine_gwas_results.tsv\"\nres.to_csv(out, sep=\"\\t\", index=False)\nprint(\"Wrote:\", out, \"rows:\", len(res))"
    }
  ],
  "metadata": {
    "colab": {
      "name": "sgkit_gwas_colab_classroom.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "accelerator": "CPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}