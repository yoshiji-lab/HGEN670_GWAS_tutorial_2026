{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Toy GWAS in Google Colab (simulated but realistic)\n",
        "\n",
        "This notebook simulates genotype data with mild population structure, generates a phenotype, and runs a GWAS twice:\n",
        "\n",
        "1) **Unadjusted** (shows inflation)\n",
        "2) **Adjusted for PCs** (reduces confounding)\n",
        "\n",
        "It then makes **Manhattan** and **QQ** plots.\n",
        "\n",
        "> Designed to run in a few minutes on Colab."
      ],
      "id": "252e179e-6690-4718-93a8-82b0a5a35d58"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title Setup\n",
        "!pip -q install numpy pandas scipy statsmodels scikit-learn matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "40d7e5e9-e7fd-4437-bcaa-2a41d7d4f4f9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Simulate genotypes with mild population structure\n",
        "\n",
        "We simulate two subpopulations with slightly different allele frequencies (a simple way to create confounding)."
      ],
      "id": "d640c050-be6a-4574-a7ea-8ef4d60f7250"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title Simulate genotypes\n",
        "n = 2000          # individuals\n",
        "m = 12000         # SNPs (keep moderate for Colab speed)\n",
        "\n",
        "# random minor allele frequencies\n",
        "maf = np.random.uniform(0.05, 0.5, size=m)\n",
        "\n",
        "# two populations (0/1)\n",
        "pop = np.random.binomial(1, 0.5, size=n)\n",
        "\n",
        "# allele-frequency shift between populations (small)\n",
        "delta = np.random.normal(0, 0.03, size=m)  # mild structure\n",
        "maf_pop1 = np.clip(maf + delta, 0.01, 0.99)\n",
        "maf_pop0 = np.clip(maf - delta, 0.01, 0.99)\n",
        "\n",
        "# genotype matrix G: n x m, coded 0/1/2\n",
        "G = np.empty((n, m), dtype=np.int8)\n",
        "for i in range(n):\n",
        "    p = maf_pop1 if pop[i] == 1 else maf_pop0\n",
        "    G[i, :] = np.random.binomial(2, p).astype(np.int8)\n",
        "\n",
        "# quick QC: remove monomorphic SNPs (should be rare here)\n",
        "var = G.var(axis=0)\n",
        "keep = var > 0\n",
        "G = G[:, keep]\n",
        "maf = maf[keep]\n",
        "m = G.shape[1]\n",
        "\n",
        "print(f\"Genotypes: n={n}, m={m}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "37b34f1e-c95e-4b56-b7c0-6a8a9a6136b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Create a phenotype\n",
        "\n",
        "We pick a few causal SNPs, add a small population effect (confounding), and add noise."
      ],
      "id": "1a136a4f-c533-485f-b310-791d504b19e5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title Simulate phenotype\n",
        "n_causal = 20\n",
        "causal_idx = np.random.choice(m, size=n_causal, replace=False)\n",
        "beta_causal = np.random.normal(0, 0.25, size=n_causal)\n",
        "\n",
        "genetic_signal = G[:, causal_idx] @ beta_causal\n",
        "pop_effect = 0.6 * (pop - pop.mean())          # confounding\n",
        "noise = np.random.normal(0, 1.0, size=n)\n",
        "\n",
        "y = (genetic_signal + pop_effect + noise)\n",
        "y = (y - y.mean()) / y.std()\n",
        "\n",
        "pheno = pd.DataFrame({\"iid\": np.arange(n), \"pop\": pop, \"y\": y})\n",
        "pheno.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "4bbf81ee-c89a-4a7c-96e7-31a74ef9916b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Compute PCs\n",
        "\n",
        "In real GWAS, PCs are computed from genotype data to capture ancestry-related structure."
      ],
      "id": "0b3d6be5-155e-4e4e-a9bf-25f46e6545ab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title PCA\n",
        "# standardize variants for PCA\n",
        "G_std = (G - G.mean(axis=0)) / G.std(axis=0)\n",
        "pca = PCA(n_components=5, random_state=42)\n",
        "pcs = pca.fit_transform(G_std)\n",
        "\n",
        "for k in range(5):\n",
        "    pheno[f\"PC{k+1}\"] = pcs[:, k]\n",
        "\n",
        "pheno[[\"pop\",\"PC1\",\"PC2\",\"PC3\"]].corr()"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "3a2f1474-e4c6-4e39-9bfb-a00b43a1478b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) GWAS (fast linear regression)\n",
        "\n",
        "We implement association testing by residualizing **y** and each SNP on covariates, then using the correlation test. This is fast and transparent for teaching.\n",
        "\n",
        "- **Unadjusted:** no covariates\n",
        "- **Adjusted:** covariates = PC1\u2013PC5"
      ],
      "id": "2e4b5a63-a77c-4126-b6ea-1839888d92dd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title Helper: residualize and run GWAS\n",
        "def residualize(v, X):\n",
        "    # v: (n,), X: (n,k) with intercept included\n",
        "    beta, *_ = np.linalg.lstsq(X, v, rcond=None)\n",
        "    return v - X @ beta\n",
        "\n",
        "def gwas_linear(G, y, cov=None):\n",
        "    n, m = G.shape\n",
        "    if cov is None:\n",
        "        X = np.ones((n,1))\n",
        "    else:\n",
        "        X = np.column_stack([np.ones(n), cov])\n",
        "    y_r = residualize(y, X)\n",
        "\n",
        "    # residualize each SNP on covariates (loop over chunks for memory)\n",
        "    betas = np.zeros(m, dtype=float)\n",
        "    ses = np.zeros(m, dtype=float)\n",
        "    pvals = np.zeros(m, dtype=float)\n",
        "\n",
        "    chunk = 2000\n",
        "    for start in range(0, m, chunk):\n",
        "        end = min(m, start + chunk)\n",
        "        Gc = G[:, start:end].astype(float)\n",
        "\n",
        "        # residualize SNPs\n",
        "        # Solve (X'X)^{-1}X'G for each SNP using lstsq\n",
        "        B, *_ = np.linalg.lstsq(X, Gc, rcond=None)  # (k+1) x chunk\n",
        "        Gc_r = Gc - X @ B\n",
        "\n",
        "        # association using simple regression y_r ~ Gc_r\n",
        "        # beta = cov / var\n",
        "        cov_y = (Gc_r * y_r[:, None]).sum(axis=0)\n",
        "        var_g = (Gc_r ** 2).sum(axis=0)\n",
        "        beta = cov_y / var_g\n",
        "\n",
        "        # SE from residual variance\n",
        "        resid = y_r[:, None] - Gc_r * beta[None, :]\n",
        "        sigma2 = (resid**2).sum(axis=0) / (n - X.shape[1] - 1)\n",
        "        se = np.sqrt(sigma2 / var_g)\n",
        "\n",
        "        z = beta / se\n",
        "        p = 2 * stats.norm.sf(np.abs(z))\n",
        "\n",
        "        betas[start:end] = beta\n",
        "        ses[start:end] = se\n",
        "        pvals[start:end] = p\n",
        "\n",
        "    return betas, ses, pvals\n",
        "\n",
        "# run both\n",
        "cov_pcs = pheno[[f\"PC{k+1}\" for k in range(5)]].to_numpy()\n",
        "beta0, se0, p0 = gwas_linear(G, y, cov=None)\n",
        "beta1, se1, p1 = gwas_linear(G, y, cov=cov_pcs)\n",
        "\n",
        "print(\"Done.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "cc5d27e6-2313-463a-a5bf-6b4bf8f41cd5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Summaries: inflation (\u03bbGC) and top hits"
      ],
      "id": "946d53ef-be27-48a5-bd64-5d5bd5e647d1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title Summaries\n",
        "def lambda_gc(pvals):\n",
        "    chi2 = stats.chi2.isf(pvals, df=1)\n",
        "    return np.median(chi2) / stats.chi2.ppf(0.5, df=1)\n",
        "\n",
        "lam0 = lambda_gc(p0)\n",
        "lam1 = lambda_gc(p1)\n",
        "\n",
        "print(f\"Lambda GC (unadjusted): {lam0:.3f}\")\n",
        "print(f\"Lambda GC (PC-adjusted): {lam1:.3f}\")\n",
        "\n",
        "# top SNPs\n",
        "top = np.argsort(p1)[:20]\n",
        "top_df = pd.DataFrame({\n",
        "    \"snp_index\": top,\n",
        "    \"beta_adj\": beta1[top],\n",
        "    \"se_adj\": se1[top],\n",
        "    \"p_adj\": p1[top],\n",
        "    \"is_causal\": np.isin(top, causal_idx)\n",
        "}).sort_values(\"p_adj\")\n",
        "\n",
        "top_df"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "8cf9dd2c-1ed2-4081-8b0a-a5989aa0577e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Manhattan + QQ plots\n",
        "\n",
        "We generate fake chromosome/position coordinates (so the plots look like a real GWAS)."
      ],
      "id": "7fe9e419-f4b5-47c4-9b55-e130d4404354"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title Create synthetic genomic coordinates\n",
        "# assign SNPs to chromosomes\n",
        "chroms = np.repeat(np.arange(1, 23), np.ceil(m / 22).astype(int))[:m]\n",
        "# positions within chromosome\n",
        "pos = np.zeros(m, dtype=int)\n",
        "for c in range(1, 23):\n",
        "    idx = np.where(chroms == c)[0]\n",
        "    pos[idx] = np.sort(np.random.randint(1, 50_000_000, size=len(idx)))\n",
        "\n",
        "# cumulative position for Manhattan\n",
        "chrom_max = pd.Series(pos).groupby(chroms).max()\n",
        "offsets = chrom_max.cumsum().shift(fill_value=0).to_dict()\n",
        "x = pos + np.array([offsets[c] for c in chroms])\n",
        "\n",
        "coord = pd.DataFrame({\"chr\": chroms, \"pos\": pos, \"x\": x, \"p_unadj\": p0, \"p_adj\": p1})\n",
        "coord.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "4ba47233-13c3-4a0f-83fe-4b487d737c40"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title Manhattan plot (PC-adjusted)\n",
        "df = coord.sort_values([\"chr\",\"pos\"])\n",
        "df[\"mlog10p\"] = -np.log10(df[\"p_adj\"].clip(1e-300, 1.0))\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.scatter(df[\"x\"], df[\"mlog10p\"], s=4, alpha=0.7)\n",
        "plt.axhline(-np.log10(5e-8), linestyle=\"--\")  # genome-wide threshold\n",
        "plt.xlabel(\"Genomic position (synthetic)\")\n",
        "plt.ylabel(\"-log10(P)\")\n",
        "plt.title(\"Toy GWAS Manhattan plot (PC-adjusted)\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "f89e7907-e2fd-4ca5-a1eb-a66f84e9704f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title QQ plots (unadjusted vs adjusted)\n",
        "def qqplot(pvals, title):\n",
        "    p = np.sort(pvals)\n",
        "    exp = -np.log10((np.arange(1, len(p)+1) - 0.5) / len(p))\n",
        "    obs = -np.log10(p.clip(1e-300, 1.0))\n",
        "    plt.figure(figsize=(4.5,4.5))\n",
        "    plt.scatter(exp, obs, s=6, alpha=0.7)\n",
        "    mx = max(exp.max(), obs.max())\n",
        "    plt.plot([0,mx],[0,mx], linestyle=\"--\")\n",
        "    plt.xlabel(\"Expected -log10(P)\")\n",
        "    plt.ylabel(\"Observed -log10(P)\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "qqplot(p0, f\"QQ plot (unadjusted), lambda={lam0:.2f}\")\n",
        "qqplot(p1, f\"QQ plot (PC-adjusted), lambda={lam1:.2f}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "54bfadcf-355f-47ea-90c5-58e118a26bb1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Teaching notes (quick talking points)\n",
        "\n",
        "- Why population structure inflates test statistics\n",
        "- What PCs capture\n",
        "- Manhattan vs QQ\n",
        "- \u03bbGC and why it is not a perfect diagnostic (but useful for demos)\n"
      ],
      "id": "4341ebac-88b8-49b0-95f2-5c30556ed794"
    }
  ],
  "metadata": {
    "colab": {
      "name": "toy_gwas_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}