{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "252e179e-6690-4718-93a8-82b0a5a35d58",
      "metadata": {},
      "source": [
        "# Toy GWAS in Google Colab (simulated but realistic)\n",
        "\n",
        "## What is GWAS?\n",
        "\n",
        "**Genome-Wide Association Studies (GWAS)** test millions of genetic variants (SNPs) across the genome to find associations with a trait or disease. The goal is to identify which genetic variants are associated with the phenotype of interest.\n",
        "\n",
        "## What you'll learn in this notebook:\n",
        "\n",
        "1. **How to simulate realistic genetic data** with population structure\n",
        "2. **Why population structure causes confounding** in GWAS\n",
        "3. **How Principal Components (PCs) help control for confounding**\n",
        "4. **How to interpret Manhattan plots and QQ plots**\n",
        "5. **The difference between unadjusted and adjusted GWAS results**\n",
        "\n",
        "This notebook simulates genotype data with mild population structure, generates a phenotype, and runs a GWAS twice:\n",
        "\n",
        "1) **Unadjusted** (shows inflation due to population structure)\n",
        "2) **Adjusted for PCs** (reduces confounding)\n",
        "\n",
        "It then makes **Manhattan** and **QQ** plots to visualize the results.\n",
        "\n",
        "> Designed to run in a few minutes on Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40d7e5e9-e7fd-4437-bcaa-2a41d7d4f4f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Setup\n",
        "!pip -q install numpy pandas scipy statsmodels scikit-learn matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d640c050-be6a-4574-a7ea-8ef4d60f7250",
      "metadata": {},
      "source": [
        "## 1) Simulate genotypes with mild population structure\n",
        "\n",
        "### Why simulate population structure?\n",
        "\n",
        "In real genetic data, individuals from different populations (e.g., different ancestries) have different allele frequencies. This creates **population structure** - a correlation between genetic variants and population membership.\n",
        "\n",
        "**Why this matters for GWAS:** If your phenotype also differs between populations (e.g., due to environmental factors), you might find \"significant\" associations that are actually just due to population differences, not true genetic effects. This is called **confounding** or **population stratification**.\n",
        "\n",
        "### What we're doing:\n",
        "\n",
        "We simulate two subpopulations with slightly different allele frequencies. This creates a simple form of population structure that will cause confounding in our GWAS if we don't control for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b34f1e-c95e-4b56-b7c0-6a8a9a6136b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Simulate genotypes\n",
        "n = 2000          # individuals\n",
        "m = 12000         # SNPs (keep moderate for Colab speed)\n",
        "\n",
        "# random minor allele frequencies\n",
        "maf = np.random.uniform(0.05, 0.5, size=m)\n",
        "\n",
        "# two populations (0/1)\n",
        "pop = np.random.binomial(1, 0.5, size=n)\n",
        "\n",
        "# allele-frequency shift between populations (small)\n",
        "delta = np.random.normal(0, 0.03, size=m)  # mild structure\n",
        "maf_pop1 = np.clip(maf + delta, 0.01, 0.99)\n",
        "maf_pop0 = np.clip(maf - delta, 0.01, 0.99)\n",
        "\n",
        "# genotype matrix G: n x m, coded 0/1/2\n",
        "G = np.empty((n, m), dtype=np.int8)\n",
        "for i in range(n):\n",
        "    p = maf_pop1 if pop[i] == 1 else maf_pop0\n",
        "    G[i, :] = np.random.binomial(2, p).astype(np.int8)\n",
        "\n",
        "# quick QC: remove monomorphic SNPs (should be rare here)\n",
        "var = G.var(axis=0)\n",
        "keep = var > 0\n",
        "G = G[:, keep]\n",
        "maf = maf[keep]\n",
        "m = G.shape[1]\n",
        "\n",
        "print(f\"Genotypes: n={n}, m={m}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a136a4f-c533-485f-b310-791d504b19e5",
      "metadata": {},
      "source": [
        "## 2) Create a phenotype\n",
        "\n",
        "### How we simulate the phenotype:\n",
        "\n",
        "1. **Genetic signal:** We pick a few \"causal\" SNPs that truly affect the phenotype\n",
        "2. **Population effect (confounding):** We add an effect that differs between populations - this mimics real-world scenarios where environmental or cultural factors differ by population\n",
        "3. **Noise:** We add random noise to make it realistic\n",
        "\n",
        "**Key point:** The population effect creates confounding because:\n",
        "- Population membership is correlated with genotype (due to different allele frequencies)\n",
        "- Population membership also affects the phenotype\n",
        "- This creates a spurious association between genotype and phenotype, even for non-causal SNPs!\n",
        "\n",
        "This is why we need to control for population structure in GWAS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bbf81ee-c89a-4a7c-96e7-31a74ef9916b",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Simulate phenotype\n",
        "n_causal = 20\n",
        "causal_idx = np.random.choice(m, size=n_causal, replace=False)\n",
        "beta_causal = np.random.normal(0, 0.25, size=n_causal)\n",
        "\n",
        "genetic_signal = G[:, causal_idx] @ beta_causal\n",
        "pop_effect = 0.6 * (pop - pop.mean())          # confounding\n",
        "noise = np.random.normal(0, 1.0, size=n)\n",
        "\n",
        "y = (genetic_signal + pop_effect + noise)\n",
        "y = (y - y.mean()) / y.std()\n",
        "\n",
        "pheno = pd.DataFrame({\"iid\": np.arange(n), \"pop\": pop, \"y\": y})\n",
        "pheno.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b3d6be5-155e-4e4e-a9bf-25f46e6545ab",
      "metadata": {},
      "source": [
        "## 3) Compute Principal Components (PCs)\n",
        "\n",
        "### What are Principal Components?\n",
        "\n",
        "**Principal Component Analysis (PCA)** is a dimensionality reduction technique. When applied to genotype data, the first few PCs capture the major axes of genetic variation, which often correspond to population structure.\n",
        "\n",
        "### Why use PCs in GWAS?\n",
        "\n",
        "- **PCs capture population structure:** The first few PCs typically capture ancestry-related differences\n",
        "- **They can be used as covariates:** By including PCs as covariates in the regression model, we can control for population structure\n",
        "- **This reduces false positives:** SNPs that appear significant only due to population differences will no longer be significant after adjusting for PCs\n",
        "\n",
        "### What to look for:\n",
        "\n",
        "The correlation between `pop` and `PC1` should be high - this shows that PC1 is capturing the population structure we simulated!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a2f1474-e4c6-4e39-9bfb-a00b43a1478b",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title PCA\n",
        "# standardize variants for PCA\n",
        "G_std = (G - G.mean(axis=0)) / G.std(axis=0)\n",
        "pca = PCA(n_components=5, random_state=42)\n",
        "pcs = pca.fit_transform(G_std)\n",
        "\n",
        "for k in range(5):\n",
        "    pheno[f\"PC{k+1}\"] = pcs[:, k]\n",
        "\n",
        "pheno[[\"pop\",\"PC1\",\"PC2\",\"PC3\"]].corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e4b5a63-a77c-4126-b6ea-1839888d92dd",
      "metadata": {},
      "source": [
        "## 4) GWAS (fast linear regression)\n",
        "\n",
        "### How GWAS works:\n",
        "\n",
        "For each SNP, we test the association between genotype and phenotype using linear regression:\n",
        "\n",
        "**Phenotype = intercept + (SNP effect × genotype) + covariates + error**\n",
        "\n",
        "### Two approaches:\n",
        "\n",
        "1. **Unadjusted GWAS:** No covariates included\n",
        "   - Will show **inflation** (too many significant results) due to population structure\n",
        "   - This demonstrates the problem of confounding\n",
        "\n",
        "2. **Adjusted GWAS:** Includes PC1–PC5 as covariates\n",
        "   - Controls for population structure\n",
        "   - Should show fewer false positives\n",
        "\n",
        "### Implementation details:\n",
        "\n",
        "We use a fast approach: residualize both the phenotype and each SNP on the covariates, then test the correlation between the residuals. This is mathematically equivalent to including covariates in the regression but computationally faster.\n",
        "\n",
        "**Key question:** Will the adjusted GWAS show less inflation than the unadjusted one?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5d27e6-2313-463a-a5bf-6b4bf8f41cd5",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Helper: residualize and run GWAS\n",
        "def residualize(v, X):\n",
        "    # v: (n,), X: (n,k) with intercept included\n",
        "    beta, *_ = np.linalg.lstsq(X, v, rcond=None)\n",
        "    return v - X @ beta\n",
        "\n",
        "def gwas_linear(G, y, cov=None):\n",
        "    n, m = G.shape\n",
        "    if cov is None:\n",
        "        X = np.ones((n,1))\n",
        "    else:\n",
        "        X = np.column_stack([np.ones(n), cov])\n",
        "    y_r = residualize(y, X)\n",
        "\n",
        "    # residualize each SNP on covariates (loop over chunks for memory)\n",
        "    betas = np.zeros(m, dtype=float)\n",
        "    ses = np.zeros(m, dtype=float)\n",
        "    pvals = np.zeros(m, dtype=float)\n",
        "\n",
        "    chunk = 2000\n",
        "    for start in range(0, m, chunk):\n",
        "        end = min(m, start + chunk)\n",
        "        Gc = G[:, start:end].astype(float)\n",
        "\n",
        "        # residualize SNPs\n",
        "        # Solve (X'X)^{-1}X'G for each SNP using lstsq\n",
        "        B, *_ = np.linalg.lstsq(X, Gc, rcond=None)  # (k+1) x chunk\n",
        "        Gc_r = Gc - X @ B\n",
        "\n",
        "        # association using simple regression y_r ~ Gc_r\n",
        "        # beta = cov / var\n",
        "        cov_y = (Gc_r * y_r[:, None]).sum(axis=0)\n",
        "        var_g = (Gc_r ** 2).sum(axis=0)\n",
        "        beta = cov_y / var_g\n",
        "\n",
        "        # SE from residual variance\n",
        "        resid = y_r[:, None] - Gc_r * beta[None, :]\n",
        "        sigma2 = (resid**2).sum(axis=0) / (n - X.shape[1] - 1)\n",
        "        se = np.sqrt(sigma2 / var_g)\n",
        "\n",
        "        z = beta / se\n",
        "        p = 2 * stats.norm.sf(np.abs(z))\n",
        "\n",
        "        betas[start:end] = beta\n",
        "        ses[start:end] = se\n",
        "        pvals[start:end] = p\n",
        "\n",
        "    return betas, ses, pvals\n",
        "\n",
        "# run both\n",
        "cov_pcs = pheno[[f\"PC{k+1}\" for k in range(5)]].to_numpy()\n",
        "beta0, se0, p0 = gwas_linear(G, y, cov=None)\n",
        "beta1, se1, p1 = gwas_linear(G, y, cov=cov_pcs)\n",
        "\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "946d53ef-be27-48a5-bd64-5d5bd5e647d1",
      "metadata": {},
      "source": [
        "## 5) Summaries: inflation (λGC) and top hits\n",
        "\n",
        "### Lambda GC (λGC) - Genomic Control\n",
        "\n",
        "**Lambda GC** is a measure of test statistic inflation:\n",
        "- **λGC = 1.0:** No inflation (perfect null distribution)\n",
        "- **λGC > 1.0:** Inflation (too many significant results)\n",
        "- **λGC < 1.0:** Deflation (too few significant results)\n",
        "\n",
        "**What causes inflation?**\n",
        "- Population structure (confounding)\n",
        "- Cryptic relatedness\n",
        "- Other systematic biases\n",
        "\n",
        "**What to expect:**\n",
        "- **Unadjusted:** λGC should be > 1.0 (inflation due to population structure)\n",
        "- **Adjusted:** λGC should be closer to 1.0 (inflation reduced by controlling for PCs)\n",
        "\n",
        "**Note:** λGC is not perfect - it can miss some types of confounding, but it's a useful diagnostic tool.\n",
        "\n",
        "### Top hits:\n",
        "\n",
        "Let's look at the most significant SNPs. Some should be the causal SNPs we simulated (marked as `is_causal=True`), but we might also see some false positives in the unadjusted analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf9dd2c-1ed2-4081-8b0a-a5989aa0577e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Summaries\n",
        "def lambda_gc(pvals):\n",
        "    chi2 = stats.chi2.isf(pvals, df=1)\n",
        "    return np.median(chi2) / stats.chi2.ppf(0.5, df=1)\n",
        "\n",
        "lam0 = lambda_gc(p0)\n",
        "lam1 = lambda_gc(p1)\n",
        "\n",
        "print(f\"Lambda GC (unadjusted): {lam0:.3f}\")\n",
        "print(f\"Lambda GC (PC-adjusted): {lam1:.3f}\")\n",
        "\n",
        "# top SNPs\n",
        "top = np.argsort(p1)[:20]\n",
        "top_df = pd.DataFrame({\n",
        "    \"snp_index\": top,\n",
        "    \"beta_adj\": beta1[top],\n",
        "    \"se_adj\": se1[top],\n",
        "    \"p_adj\": p1[top],\n",
        "    \"is_causal\": np.isin(top, causal_idx)\n",
        "}).sort_values(\"p_adj\")\n",
        "\n",
        "top_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe9e419-f4b5-47c4-9b55-e130d4404354",
      "metadata": {},
      "source": [
        "## 6) Manhattan + QQ plots\n",
        "\n",
        "### What are these plots?\n",
        "\n",
        "**Manhattan Plot:**\n",
        "- Shows -log10(p-value) for each SNP across the genome\n",
        "- Each point is a SNP, positioned by its genomic location\n",
        "- Horizontal line shows the genome-wide significance threshold (typically p < 5×10⁻⁸)\n",
        "- **\"Towers\"** of significant SNPs indicate regions with true associations (due to linkage disequilibrium - nearby SNPs are correlated)\n",
        "\n",
        "**QQ Plot (Quantile-Quantile):**\n",
        "- Compares observed p-values to expected p-values under the null hypothesis\n",
        "- Points on the diagonal = no inflation\n",
        "- Points above the diagonal = inflation (too many small p-values)\n",
        "- The \"tail\" of the plot (right side) shows the most significant results\n",
        "\n",
        "### Synthetic coordinates:\n",
        "\n",
        "We generate fake chromosome/position coordinates so the plots look like a real GWAS. In practice, you'd use the actual genomic positions from your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ba47233-13c3-4a0f-83fe-4b487d737c40",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Create synthetic genomic coordinates\n",
        "# assign SNPs to chromosomes (autosomes 1-22)\n",
        "chroms = np.repeat(np.arange(1, 23), np.ceil(m / 22).astype(int))[:m]\n",
        "# positions within chromosome (random but sorted)\n",
        "pos = np.zeros(m, dtype=int)\n",
        "for c in range(1, 23):\n",
        "    idx = np.where(chroms == c)[0]\n",
        "    pos[idx] = np.sort(np.random.randint(1, 50_000_000, size=len(idx)))\n",
        "\n",
        "# cumulative position for Manhattan plot (so chromosomes appear side-by-side)\n",
        "chrom_max = pd.Series(pos).groupby(chroms).max()\n",
        "offsets = chrom_max.cumsum().shift(fill_value=0).to_dict()\n",
        "x = pos + np.array([offsets[c] for c in chroms])\n",
        "\n",
        "coord = pd.DataFrame({\"chr\": chroms, \"pos\": pos, \"x\": x, \"p_unadj\": p0, \"p_adj\": p1})\n",
        "print(\"Created synthetic genomic coordinates:\")\n",
        "coord.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f89e7907-e2fd-4ca5-a1eb-a66f84e9704f",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Helper function: Simulate LD effects to create realistic \"towers\"\n",
        "def add_ld_effects(coord_df, pvals, causal_idx, window_size=500000):\n",
        "    \"\"\"\n",
        "    Simulate linkage disequilibrium (LD) effects.\n",
        "    When a causal SNP is significant, nearby SNPs also become more significant\n",
        "    due to correlation (LD). This creates the \"tower\" effect in Manhattan plots.\n",
        "    \"\"\"\n",
        "    pvals_ld = pvals.copy()\n",
        "    coord_reset = coord_df.reset_index(drop=True)  # Ensure 0-based integer index\n",
        "    \n",
        "    # For each causal SNP that's significant, boost nearby SNPs\n",
        "    for idx in causal_idx:\n",
        "        if pvals[idx] < 0.01:  # if causal SNP is at least nominally significant\n",
        "            # Find SNPs on same chromosome within window\n",
        "            chr_num = coord_reset.iloc[idx][\"chr\"]\n",
        "            pos_causal = coord_reset.iloc[idx][\"pos\"]\n",
        "            \n",
        "            same_chr = coord_reset[\"chr\"] == chr_num\n",
        "            within_window = np.abs(coord_reset[\"pos\"] - pos_causal) < window_size\n",
        "            \n",
        "            nearby = same_chr & within_window\n",
        "            nearby_positions = np.where(nearby)[0]  # Get positional indices\n",
        "            \n",
        "            # Boost p-values of nearby SNPs (make them more significant)\n",
        "            # The boost decays with distance\n",
        "            for nidx in nearby_positions:\n",
        "                if nidx != idx:\n",
        "                    dist = abs(coord_reset.iloc[nidx][\"pos\"] - pos_causal)\n",
        "                    decay = np.exp(-dist / (window_size / 3))\n",
        "                    # Make p-value smaller (more significant) by a factor\n",
        "                    # Stronger effect if causal SNP is highly significant\n",
        "                    boost_factor = 0.9 * decay if pvals[idx] < 0.001 else 0.7 * decay\n",
        "                    pvals_ld[nidx] = pvals_ld[nidx] * (1 - boost_factor)\n",
        "    \n",
        "    return np.clip(pvals_ld, 1e-300, 1.0)\n",
        "\n",
        "# Add LD effects to make plots more realistic\n",
        "# Reset index to ensure proper alignment\n",
        "coord_reset = coord.reset_index(drop=True)\n",
        "p0_ld = add_ld_effects(coord_reset, p0, causal_idx)\n",
        "p1_ld = add_ld_effects(coord_reset, p1, causal_idx)\n",
        "\n",
        "# Update coord with LD-adjusted p-values\n",
        "coord[\"p_unadj_ld\"] = p0_ld\n",
        "coord[\"p_adj_ld\"] = p1_ld\n",
        "print(\"Added LD effects to create realistic 'towers' in Manhattan plots\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efd17114",
      "metadata": {},
      "source": [
        "### Manhattan Plot: Unadjusted GWAS\n",
        "\n",
        "This plot shows the results **without** controlling for population structure. Notice:\n",
        "- Many SNPs appear significant (above the threshold line)\n",
        "- This is **inflation** - many of these are false positives due to population structure\n",
        "- The QQ plot will show this as points above the diagonal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "472d58ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Manhattan plot (Unadjusted - shows inflation)\n",
        "def plot_manhattan(coord_df, pvals_col, title, figsize=(14, 5)):\n",
        "    \"\"\"Create a Manhattan plot with alternating chromosome colors\"\"\"\n",
        "    df = coord_df.sort_values([\"chr\", \"pos\"]).copy()\n",
        "    df[\"mlog10p\"] = -np.log10(df[pvals_col].clip(1e-300, 1.0))\n",
        "    \n",
        "    # Color alternating chromosomes\n",
        "    colors = ['#2E86AB', '#A23B72']  # Blue and purple\n",
        "    df['color'] = df['chr'] % 2\n",
        "    df['color'] = df['color'].map({0: colors[0], 1: colors[1]})\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    # Plot each chromosome separately for better color control\n",
        "    for chr_num in sorted(df['chr'].unique()):\n",
        "        chr_data = df[df['chr'] == chr_num]\n",
        "        color = colors[chr_num % 2]\n",
        "        plt.scatter(chr_data[\"x\"], chr_data[\"mlog10p\"], \n",
        "                   s=8, alpha=0.6, c=color, label=None)\n",
        "    \n",
        "    # Genome-wide significance threshold\n",
        "    plt.axhline(-np.log10(5e-8), color='red', linestyle='--', \n",
        "               linewidth=1.5, label='Genome-wide significance (5×10⁻⁸)')\n",
        "    \n",
        "    # Suggestive threshold\n",
        "    plt.axhline(-np.log10(1e-5), color='orange', linestyle='--', \n",
        "               linewidth=1, alpha=0.7, label='Suggestive (1×10⁻⁵)')\n",
        "    \n",
        "    # Chromosome boundaries\n",
        "    chr_boundaries = []\n",
        "    for c in sorted(df['chr'].unique()):\n",
        "        chr_data = df[df['chr'] == c]\n",
        "        chr_boundaries.append(chr_data['x'].min())\n",
        "    chr_boundaries.append(df['x'].max())\n",
        "    \n",
        "    for boundary in chr_boundaries[1:-1]:\n",
        "        plt.axvline(boundary, color='gray', linestyle=':', alpha=0.3, linewidth=0.5)\n",
        "    \n",
        "    plt.xlabel(\"Chromosome\", fontsize=12)\n",
        "    plt.ylabel(\"-log₁₀(P-value)\", fontsize=12)\n",
        "    plt.title(title, fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc='upper right', fontsize=9)\n",
        "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    \n",
        "    # Set x-axis to show chromosome numbers\n",
        "    chr_centers = []\n",
        "    chr_labels = []\n",
        "    for c in sorted(df['chr'].unique()):\n",
        "        chr_data = df[df['chr'] == c]\n",
        "        chr_centers.append(chr_data['x'].mean())\n",
        "        chr_labels.append(str(int(c)))\n",
        "    plt.xticks(chr_centers, chr_labels, rotation=0)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_manhattan(coord, \"p_unadj_ld\", \n",
        "               \"Manhattan Plot: Unadjusted GWAS (shows inflation due to population structure)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4391a3de",
      "metadata": {},
      "source": [
        "### Manhattan Plot: PC-Adjusted GWAS\n",
        "\n",
        "This plot shows the results **after** controlling for population structure using PCs. Notice:\n",
        "- Fewer SNPs appear significant (inflation reduced)\n",
        "- The \"towers\" of significant SNPs indicate regions with true genetic associations\n",
        "- These towers occur because of **linkage disequilibrium (LD)** - nearby SNPs are correlated, so when a causal variant is significant, nearby SNPs also show significance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b3a897c",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Manhattan plot (PC-adjusted - inflation controlled)\n",
        "plot_manhattan(coord, \"p_adj_ld\", \n",
        "               \"Manhattan Plot: PC-Adjusted GWAS (population structure controlled)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54bfadcf-355f-47ea-90c5-58e118a26bb1",
      "metadata": {},
      "outputs": [],
      "source": [
        "### QQ Plots: Comparing Unadjusted vs Adjusted\n",
        "\n",
        "**What to look for:**\n",
        "- **Diagonal line:** Expected under the null hypothesis (no associations)\n",
        "- **Points above diagonal:** More significant results than expected (inflation)\n",
        "- **Points below diagonal:** Fewer significant results than expected (deflation)\n",
        "\n",
        "**Unadjusted plot:** Should show clear inflation (points above diagonal), especially in the tail\n",
        "**Adjusted plot:** Should be closer to the diagonal, showing that controlling for PCs reduced inflation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7260015",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title QQ plots (unadjusted vs adjusted)\n",
        "def qqplot(pvals, title, lambda_gc=None):\n",
        "    \"\"\"Create a QQ plot comparing observed vs expected p-values\"\"\"\n",
        "    p = np.sort(pvals)\n",
        "    n = len(p)\n",
        "    exp = -np.log10((np.arange(1, n+1) - 0.5) / n)\n",
        "    obs = -np.log10(p.clip(1e-300, 1.0))\n",
        "    \n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.scatter(exp, obs, s=8, alpha=0.6, edgecolors='none')\n",
        "    \n",
        "    # Diagonal line (expected under null)\n",
        "    mx = max(exp.max(), obs.max())\n",
        "    plt.plot([0, mx], [0, mx], 'r--', linewidth=1.5, label='Expected (null)')\n",
        "    \n",
        "    plt.xlabel(\"Expected -log₁₀(P-value)\", fontsize=11)\n",
        "    plt.ylabel(\"Observed -log₁₀(P-value)\", fontsize=11)\n",
        "    \n",
        "    title_text = title\n",
        "    if lambda_gc is not None:\n",
        "        title_text += f\"\\nλGC = {lambda_gc:.3f}\"\n",
        "    plt.title(title_text, fontsize=12, fontweight='bold')\n",
        "    plt.legend(loc='lower right', fontsize=9)\n",
        "    plt.grid(alpha=0.3, linestyle='--')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "qqplot(p0, \"QQ Plot: Unadjusted GWAS\", lambda_gc=lam0)\n",
        "qqplot(p1, \"QQ Plot: PC-Adjusted GWAS\", lambda_gc=lam1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4341ebac-88b8-49b0-95f2-5c30556ed794",
      "metadata": {},
      "source": [
        "## Key Takeaways and Teaching Points\n",
        "\n",
        "### 1. Population Structure Causes Confounding\n",
        "\n",
        "**The problem:**\n",
        "- Different populations have different allele frequencies\n",
        "- If the phenotype also differs between populations (for any reason), you get spurious associations\n",
        "- This creates **false positives** - SNPs that appear significant but aren't truly causal\n",
        "\n",
        "**The solution:**\n",
        "- Control for population structure using Principal Components (PCs)\n",
        "- Include PCs as covariates in the regression model\n",
        "- This removes the spurious associations while keeping true genetic effects\n",
        "\n",
        "### 2. Principal Components Capture Population Structure\n",
        "\n",
        "- The first few PCs typically capture major axes of genetic variation\n",
        "- These often correspond to population/ancestry differences\n",
        "- By including PCs as covariates, we control for these differences\n",
        "\n",
        "### 3. Manhattan Plots Show Genome-Wide Results\n",
        "\n",
        "- Each point is a SNP, positioned by genomic location\n",
        "- Height shows -log10(p-value) - higher = more significant\n",
        "- **Towers** of significant SNPs indicate regions with true associations\n",
        "- Towers occur due to **linkage disequilibrium (LD)** - nearby SNPs are correlated\n",
        "\n",
        "### 4. QQ Plots Diagnose Inflation\n",
        "\n",
        "- Compare observed p-values to expected p-values under the null\n",
        "- Points above diagonal = inflation (too many significant results)\n",
        "- Points on diagonal = well-controlled study\n",
        "- The \"tail\" (right side) shows the most significant results\n",
        "\n",
        "### 5. Lambda GC (λGC) Measures Inflation\n",
        "\n",
        "- λGC = 1.0: No inflation (perfect)\n",
        "- λGC > 1.0: Inflation (problem!)\n",
        "- λGC < 1.0: Deflation (also a problem, but less common)\n",
        "\n",
        "**Note:** λGC is useful but not perfect - it can miss some types of confounding, and a well-powered study with true associations will also show some inflation in the tail.\n",
        "\n",
        "### 6. Real GWAS Best Practices\n",
        "\n",
        "In real GWAS studies, you should:\n",
        "1. **Quality control (QC):** Filter out low-quality SNPs and samples\n",
        "2. **Control for covariates:** PCs, age, sex, batch effects, etc.\n",
        "3. **Check for inflation:** Use QQ plots and λGC\n",
        "4. **Replication:** Significant findings should be replicated in independent datasets\n",
        "5. **Multiple testing correction:** Use appropriate thresholds (e.g., p < 5×10⁻⁸ for genome-wide significance)\n",
        "\n",
        "### Questions for Discussion\n",
        "\n",
        "1. Why does the unadjusted GWAS show more significant results?\n",
        "2. How do PCs help reduce false positives?\n",
        "3. What would happen if we didn't control for population structure in a real GWAS?\n",
        "4. Why do we see \"towers\" of significant SNPs rather than isolated points?\n",
        "5. What other factors (besides population structure) could cause inflation in a GWAS?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "toy_gwas_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
